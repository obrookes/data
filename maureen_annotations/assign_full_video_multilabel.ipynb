{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inflect\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Establish all long videos that are annotated and on disc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos stored on disc/jade2\n",
    "videos_on_disc = pd.read_csv(\"data/external/videos_on_disc.csv\")\n",
    "videos_on_disc.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "videos_on_disc[\"videos\"] = videos_on_disc[\"videos\"].str.lower()\n",
    "videos_on_disc[\"videos\"] = videos_on_disc.videos.apply(lambda x: x.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maureens annotations\n",
    "csv_files = glob(\"data/sites/csv/**/*.csv\", recursive=True)\n",
    "sorted_csv_files = sorted(csv_files, key=lambda x: x.split(\"/\")[-1])\n",
    "initialiser, remainder = sorted_csv_files[0], sorted_csv_files[1:]\n",
    "mm_df = pd.read_csv(initialiser, encoding=\"ISO-8859-1\")\n",
    "for file in remainder:\n",
    "    site = pd.read_csv(file, encoding=\"ISO-8859-1\")\n",
    "    mm_df = pd.concat([mm_df, site])\n",
    "mm_df[\"subdir_video\"] = (\n",
    "    mm_df.subfolder.astype(str) + \"_\" + mm_df.video_file_name.astype(str)\n",
    ")\n",
    "mm_df[\"subdir_video\"] = mm_df.subdir_video.str.lower()\n",
    "\n",
    "mm_df[\"prepend_zero\"] = mm_df.subdir_video.apply(\n",
    "    lambda x: f'{\"_\".join(x.split(\"_\")[:-1])}_{\"0\" + x.split(\"_\")[-1]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_row_id</th>\n",
       "      <th>country</th>\n",
       "      <th>research_site</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>cam_coverage_area</th>\n",
       "      <th>location_metadata</th>\n",
       "      <th>habitat</th>\n",
       "      <th>utm_zone</th>\n",
       "      <th>utm_long</th>\n",
       "      <th>...</th>\n",
       "      <th>tool_use</th>\n",
       "      <th>vocalization</th>\n",
       "      <th>bipedal</th>\n",
       "      <th>camera_reaction</th>\n",
       "      <th>behavioral_context</th>\n",
       "      <th>other_species</th>\n",
       "      <th>additional_comments</th>\n",
       "      <th>record_type</th>\n",
       "      <th>subdir_video</th>\n",
       "      <th>prepend_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>520</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>campo_maan</td>\n",
       "      <td>Pan</td>\n",
       "      <td>troglodytes troglodytes</td>\n",
       "      <td>24.36</td>\n",
       "      <td>termite site</td>\n",
       "      <td>forest - mixed, open understorey</td>\n",
       "      <td>32n</td>\n",
       "      <td>606473.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>tool use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tool use suspected; not clearly visible</td>\n",
       "      <td>60s_video</td>\n",
       "      <td>cmnp_cam09_606473_246762_20140821_ek000140</td>\n",
       "      <td>cmnp_cam09_606473_246762_20140821_0ek000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>521</td>\n",
       "      <td>cameroon</td>\n",
       "      <td>campo_maan</td>\n",
       "      <td>Pan</td>\n",
       "      <td>troglodytes troglodytes</td>\n",
       "      <td>24.36</td>\n",
       "      <td>termite site</td>\n",
       "      <td>forest - mixed, open understorey</td>\n",
       "      <td>32n</td>\n",
       "      <td>606473.0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>tool use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tool use suspected; not clearly visible</td>\n",
       "      <td>60s_video</td>\n",
       "      <td>cmnp_cam09_606473_246762_20140821_ek000140</td>\n",
       "      <td>cmnp_cam09_606473_246762_20140821_0ek000140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     new_row_id   country research_site genus                  species  \\\n",
       "519         520  cameroon    campo_maan   Pan  troglodytes troglodytes   \n",
       "520         521  cameroon    campo_maan   Pan  troglodytes troglodytes   \n",
       "\n",
       "     cam_coverage_area location_metadata                           habitat  \\\n",
       "519              24.36      termite site  forest - mixed, open understorey   \n",
       "520              24.36      termite site  forest - mixed, open understorey   \n",
       "\n",
       "    utm_zone  utm_long  ...  tool_use vocalization bipedal  camera_reaction  \\\n",
       "519      32n  606473.0  ...       yes           no      no               no   \n",
       "520      32n  606473.0  ...       yes           no      no               no   \n",
       "\n",
       "    behavioral_context  other_species  \\\n",
       "519           tool use            NaN   \n",
       "520           tool use            NaN   \n",
       "\n",
       "                         additional_comments  record_type  \\\n",
       "519  tool use suspected; not clearly visible    60s_video   \n",
       "520  tool use suspected; not clearly visible    60s_video   \n",
       "\n",
       "                                   subdir_video  \\\n",
       "519  cmnp_cam09_606473_246762_20140821_ek000140   \n",
       "520  cmnp_cam09_606473_246762_20140821_ek000140   \n",
       "\n",
       "                                    prepend_zero  \n",
       "519  cmnp_cam09_606473_246762_20140821_0ek000140  \n",
       "520  cmnp_cam09_606473_246762_20140821_0ek000140  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_df[mm_df.subdir_video == \"cmnp_cam09_606473_246762_20140821_ek000140\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All annotations for old and new platforms\n",
    "all_clip_info = pd.read_csv(\n",
    "    \"../maureen_annotations/data/external/all_cs_clip_information.txt\",\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "all_clip_info.subject_id = all_clip_info.subject_id.str.lower()\n",
    "all_clip_info[\"video_id\"] = all_clip_info[\"video.id\"].astype(str).str.lower()\n",
    "all_clip_info[\"video_id\"] = all_clip_info.video_id.apply(\n",
    "    lambda x: \"_\".join(x.split(\"/\")[1:])\n",
    ")\n",
    "all_clip_info[\"video_id\"] = all_clip_info.video_id.apply(lambda x: x.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>start.time</th>\n",
       "      <th>site</th>\n",
       "      <th>video.id</th>\n",
       "      <th>tags</th>\n",
       "      <th>classifications</th>\n",
       "      <th>behavior</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60886059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafing</td>\n",
       "      <td>BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHIMPANZEE,CHIMPANZEE,CHIMPANZEE,NOTHINGHERE</td>\n",
       "      <td>TRAVELING</td>\n",
       "      <td>baf_vid16_0340989_1432398_20151114_12010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60886061</td>\n",
       "      <td>15.0</td>\n",
       "      <td>bafing</td>\n",
       "      <td>BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOTHINGHERE,NOTHINGHERE,NOTHINGHERE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baf_vid16_0340989_1432398_20151114_12010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60886060</td>\n",
       "      <td>30.0</td>\n",
       "      <td>bafing</td>\n",
       "      <td>BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOTHINGHERE,NOTHINGHERE,NOTHINGHERE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baf_vid16_0340989_1432398_20151114_12010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60886062</td>\n",
       "      <td>45.0</td>\n",
       "      <td>bafing</td>\n",
       "      <td>BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOTHINGHERE,NOTHINGHERE,NOTHINGHERE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baf_vid16_0340989_1432398_20151114_12010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60886063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafing</td>\n",
       "      <td>BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...</td>\n",
       "      <td>floridpostern,chimp,1_chimp</td>\n",
       "      <td>CHIMPANZEE,CHIMPANZEE,CHIMPANZEE,CHIMPANZEE,MO...</td>\n",
       "      <td>TRAVELING</td>\n",
       "      <td>baf_vid16_0340989_1432398_20151114_12010009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33769</th>\n",
       "      <td>acp0004tfa</td>\n",
       "      <td>45.0</td>\n",
       "      <td>tair</td>\n",
       "      <td>tair_E4/tair_cam22_688836_647457_20131025/EK00...</td>\n",
       "      <td>0_chimp,chimp,muddyfrost,tool_usage</td>\n",
       "      <td>blank,blank,blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tair_cam22_688836_647457_20131025_ek000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33770</th>\n",
       "      <td>acp0004tfv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tair</td>\n",
       "      <td>tair_E4/tair_cam22_688836_647457_20131025/EK00...</td>\n",
       "      <td>1_chimp,camera_reaction,camtouch,chimp,dailyzo...</td>\n",
       "      <td>chimpanzee,chimpanzee,chimpanzee,chimpanzee,ch...</td>\n",
       "      <td>camera reaction,on the ground,playing,resting</td>\n",
       "      <td>tair_cam22_688836_647457_20131025_ek000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33771</th>\n",
       "      <td>acp0004tfw</td>\n",
       "      <td>15.0</td>\n",
       "      <td>tair</td>\n",
       "      <td>tair_E4/tair_cam22_688836_647457_20131025/EK00...</td>\n",
       "      <td>1_chimp,camera_reaction,camtouch,chimp,juvenil...</td>\n",
       "      <td>chimpanzee,chimpanzee,chimpanzee,chimpanzee,ch...</td>\n",
       "      <td>camera reaction,on the ground,playing</td>\n",
       "      <td>tair_cam22_688836_647457_20131025_ek000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33772</th>\n",
       "      <td>acp0004tfx</td>\n",
       "      <td>30.0</td>\n",
       "      <td>tair</td>\n",
       "      <td>tair_E4/tair_cam22_688836_647457_20131025/EK00...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blank,blank,blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tair_cam22_688836_647457_20131025_ek000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33773</th>\n",
       "      <td>acp0004tfy</td>\n",
       "      <td>45.0</td>\n",
       "      <td>tair</td>\n",
       "      <td>tair_E4/tair_cam22_688836_647457_20131025/EK00...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blank,blank,blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tair_cam22_688836_647457_20131025_ek000248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33774 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id  start.time    site  \\\n",
       "0        60886059         0.0  bafing   \n",
       "1        60886061        15.0  bafing   \n",
       "2        60886060        30.0  bafing   \n",
       "3        60886062        45.0  bafing   \n",
       "4        60886063         0.0  bafing   \n",
       "...           ...         ...     ...   \n",
       "33769  acp0004tfa        45.0    tair   \n",
       "33770  acp0004tfv         0.0    tair   \n",
       "33771  acp0004tfw        15.0    tair   \n",
       "33772  acp0004tfx        30.0    tair   \n",
       "33773  acp0004tfy        45.0    tair   \n",
       "\n",
       "                                                video.id  \\\n",
       "0      BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...   \n",
       "1      BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...   \n",
       "2      BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...   \n",
       "3      BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...   \n",
       "4      BAF_A8/BAF_vid16_0340989_1432398_20151114/1201...   \n",
       "...                                                  ...   \n",
       "33769  tair_E4/tair_cam22_688836_647457_20131025/EK00...   \n",
       "33770  tair_E4/tair_cam22_688836_647457_20131025/EK00...   \n",
       "33771  tair_E4/tair_cam22_688836_647457_20131025/EK00...   \n",
       "33772  tair_E4/tair_cam22_688836_647457_20131025/EK00...   \n",
       "33773  tair_E4/tair_cam22_688836_647457_20131025/EK00...   \n",
       "\n",
       "                                                    tags  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                            floridpostern,chimp,1_chimp   \n",
       "...                                                  ...   \n",
       "33769                0_chimp,chimp,muddyfrost,tool_usage   \n",
       "33770  1_chimp,camera_reaction,camtouch,chimp,dailyzo...   \n",
       "33771  1_chimp,camera_reaction,camtouch,chimp,juvenil...   \n",
       "33772                                                NaN   \n",
       "33773                                                NaN   \n",
       "\n",
       "                                         classifications  \\\n",
       "0           CHIMPANZEE,CHIMPANZEE,CHIMPANZEE,NOTHINGHERE   \n",
       "1                    NOTHINGHERE,NOTHINGHERE,NOTHINGHERE   \n",
       "2                    NOTHINGHERE,NOTHINGHERE,NOTHINGHERE   \n",
       "3                    NOTHINGHERE,NOTHINGHERE,NOTHINGHERE   \n",
       "4      CHIMPANZEE,CHIMPANZEE,CHIMPANZEE,CHIMPANZEE,MO...   \n",
       "...                                                  ...   \n",
       "33769                                  blank,blank,blank   \n",
       "33770  chimpanzee,chimpanzee,chimpanzee,chimpanzee,ch...   \n",
       "33771  chimpanzee,chimpanzee,chimpanzee,chimpanzee,ch...   \n",
       "33772                                  blank,blank,blank   \n",
       "33773                                  blank,blank,blank   \n",
       "\n",
       "                                            behavior  \\\n",
       "0                                          TRAVELING   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                          TRAVELING   \n",
       "...                                              ...   \n",
       "33769                                            NaN   \n",
       "33770  camera reaction,on the ground,playing,resting   \n",
       "33771          camera reaction,on the ground,playing   \n",
       "33772                                            NaN   \n",
       "33773                                            NaN   \n",
       "\n",
       "                                          video_id  \n",
       "0      baf_vid16_0340989_1432398_20151114_12010008  \n",
       "1      baf_vid16_0340989_1432398_20151114_12010008  \n",
       "2      baf_vid16_0340989_1432398_20151114_12010008  \n",
       "3      baf_vid16_0340989_1432398_20151114_12010008  \n",
       "4      baf_vid16_0340989_1432398_20151114_12010009  \n",
       "...                                            ...  \n",
       "33769   tair_cam22_688836_647457_20131025_ek000246  \n",
       "33770   tair_cam22_688836_647457_20131025_ek000248  \n",
       "33771   tair_cam22_688836_647457_20131025_ek000248  \n",
       "33772   tair_cam22_688836_647457_20131025_ek000248  \n",
       "33773   tair_cam22_688836_647457_20131025_ek000248  \n",
       "\n",
       "[33774 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_clip_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clip_info = all_clip_info[\n",
    "    all_clip_info.video_id.isin(videos_on_disc.videos.unique())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all the clips that have been annotated and are on disc...\n",
    "df = pd.concat(\n",
    "    [\n",
    "        all_clip_info[all_clip_info.video_id.isin(mm_df.subdir_video.unique())],\n",
    "        all_clip_info[all_clip_info.video_id.isin(mm_df.prepend_zero.unique())],\n",
    "    ]\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add multirow metadata i.e., age, sex**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = (\n",
    "    mm_df.groupby(\"subdir_video\")[\"age_class\"].apply(lambda x: list(x)).index.values\n",
    ")\n",
    "age_groups = (\n",
    "    mm_df.groupby(\"subdir_video\")[\"age_class\"]\n",
    "    .apply(\n",
    "        lambda x: \",\".join(list([str(i) for i in x]))\n",
    "        if len(list(x)) > 1\n",
    "        else list(x)[0]\n",
    "    )\n",
    "    .values\n",
    ")\n",
    "sex_groups = (\n",
    "    mm_df.groupby(\"subdir_video\")[\"sex\"]\n",
    "    .apply(\n",
    "        lambda x: \",\".join(list([str(i) for i in x]))\n",
    "        if len(list(x)) > 1\n",
    "        else list(x)[0]\n",
    "    )\n",
    "    .values\n",
    ")\n",
    "\n",
    "df = df.merge(\n",
    "    pd.DataFrame(\n",
    "        {\"subdir_video\": videos, \"age_groups\": age_groups, \"sex_groups\": sex_groups}\n",
    "    ),\n",
    "    left_on=\"video_id\",\n",
    "    right_on=\"subdir_video\",\n",
    "    how=\"inner\",\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_attr = [\n",
    "    \"subdir_video\",\n",
    "    \"country\",\n",
    "    \"research_site\",\n",
    "    \"genus\",\n",
    "    \"species\",\n",
    "    \"location_metadata\",\n",
    "    \"habitat\",\n",
    "    \"min_number_chimps_per_video\",\n",
    "    \"max_number_chimps_per_video\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"year\",\n",
    "    \"time_hr\",\n",
    "    \"time_min\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add single row metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(\n",
    "    mm_df[meta_attr], left_on=\"video_id\", right_on=\"subdir_video\", how=\"inner\"\n",
    ").drop_duplicates()\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"max_number_chimps_per_video\": \"max\",\n",
    "        \"min_number_chimps_per_video\": \"min\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add MM's behavioural information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df.rename(\n",
    "    columns={\n",
    "        \"tool_use\": \"tool_use_mm\",\n",
    "        \"vocalization\": \"vocalization_mm\",\n",
    "        \"bipedal\": \"bipedal_mm\",\n",
    "        \"camera_reaction\": \"camera_reaction_mm\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "mm_df.tool_use_mm.fillna(False, inplace=True)\n",
    "mm_df.tool_use_mm.replace(\"no\", False, inplace=True)\n",
    "mm_df.tool_use_mm.replace(\"yes\", True, inplace=True)\n",
    "\n",
    "mm_df.vocalization_mm.fillna(False, inplace=True)\n",
    "mm_df.vocalization_mm.replace(\"no\", False, inplace=True)\n",
    "mm_df.vocalization_mm.replace(\"yes\", True, inplace=True)\n",
    "\n",
    "mm_df.bipedal_mm.fillna(False, inplace=True)\n",
    "mm_df.bipedal_mm.replace(\"no\", False, inplace=True)\n",
    "mm_df.bipedal_mm.replace(\"yes\", True, inplace=True)\n",
    "\n",
    "mm_df.camera_reaction_mm.fillna(False, inplace=True)\n",
    "mm_df.camera_reaction_mm.replace(\"no\", False, inplace=True)\n",
    "mm_df.camera_reaction_mm.replace(\"yes\", True, inplace=True)\n",
    "\n",
    "mm_df.behavioral_context.fillna(False, inplace=True)\n",
    "mm_df.behavioral_context.replace(\"no\", False, inplace=True)\n",
    "mm_df.behavioral_context.replace(\"yes\", True, inplace=True)\n",
    "\n",
    "behaviour_attr = [\n",
    "    \"subdir_video\",\n",
    "    \"tool_use_mm\",\n",
    "    \"vocalization_mm\",\n",
    "    \"bipedal_mm\",\n",
    "    \"camera_reaction_mm\",\n",
    "    \"behavioral_context\",\n",
    "    \"additional_comments\",\n",
    "]\n",
    "\n",
    "df = df.merge(\n",
    "    mm_df[behaviour_attr], left_on=\"video_id\", right_on=\"subdir_video\", how=\"inner\"\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add standard multilabel behaviours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bt\"] = df.behavior.astype(str) + \",\" + df.tags.astype(str)\n",
    "df.bt = df.bt.str.lower()\n",
    "df[\"split_tags\"] = df.bt.str.split(\",\")\n",
    "df.split_tags.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.read_csv(\"data/internal/all_tags_behaviours.csv\")\n",
    "\n",
    "for col in tag_df.columns[1:]:\n",
    "    unique_tags = tag_df[tag_df[col] == col].Tags.unique()\n",
    "    df[col] = df.split_tags.apply(\n",
    "        lambda x: 1 if any(i in x for i in unique_tags) else 0\n",
    "    )\n",
    "\n",
    "# Create column indicating empties\n",
    "df[\"label_indicator\"] = (\n",
    "    df[tag_df.columns[1:]]\n",
    "    .astype(int)\n",
    "    .apply(lambda x: True if any([i for i in x]) else False, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorise into parent classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"p_camera_reaction\"] = df.camera_reaction == 1\n",
    "df[\"p_tool_use\"] = (\n",
    "    (df.tool_use == 1) | (df.termite_fishing == 1) | (df.nut_cracking == 1)\n",
    ")\n",
    "df[\"p_object_carrying\"] = df.object_carry == 1\n",
    "df[\"p_bipedal\"] = df.bipedal == 1\n",
    "df[\"p_feeding\"] = (df.feeding == 1) | (df.wood_eating == 1)\n",
    "df[\"p_chimp_carrying\"] = df.chimp_carrying == 1\n",
    "df[\"p_vocalisation\"] = (df.vocalisation == 1) | (df.hoot == 1) | (df.grunt == 1)\n",
    "df[\"p_climbing\"] = df.climbing == 1\n",
    "df[\"p_aggression\"] = (df.aggression == 1) | (df.charge == 1) | (df.fight == 1)\n",
    "df[\"p_travel\"] = (df.travel == 1) | (df.running == 1) | (df.walking == 1)\n",
    "df[\"p_sex\"] = (df.sex == 1) | (df.mounting == 1)\n",
    "df[\"p_piloerection\"] = df.piloerection == 1\n",
    "df[\"p_social_interaction\"] = (df.social_interaction == 1) | (df.nursing == 1)\n",
    "df[\"p_grooming\"] = df.grooming == 1\n",
    "df[\"p_display\"] = (\n",
    "    (df.display == 1)\n",
    "    | (df.branch_shaking == 1)\n",
    "    | (df.stone_throw == 1)\n",
    "    | (df.drumming == 1)\n",
    ")\n",
    "df[\"p_cross_species_interaction\"] = df.cross_species_interaction == 1\n",
    "df[\"p_resting\"] = df.resting == 1\n",
    "df[\"p_playing\"] = df.playing == 1\n",
    "df[\"p_no_behaviour\"] = (df.label_indicator == False) | (df.no_behaviour == 1)\n",
    "\n",
    "\n",
    "df.drop(columns=[\"camera_reaction\"], inplace=True)\n",
    "df.drop(columns=[\"tool_use\", \"termite_fishing\", \"nut_cracking\"], inplace=True)\n",
    "df.drop(columns=[\"object_carry\"], inplace=True)\n",
    "df.drop(columns=[\"bipedal\"], inplace=True)\n",
    "df.drop(columns=[\"feeding\", \"wood_eating\"], inplace=True)\n",
    "df.drop(columns=[\"chimp_carrying\"], inplace=True)\n",
    "df.drop(columns=[\"vocalisation\", \"hoot\", \"grunt\"], inplace=True)\n",
    "df.drop(columns=[\"climbing\"], inplace=True)\n",
    "df.drop(columns=[\"aggression\", \"charge\", \"fight\"], inplace=True)\n",
    "df.drop(columns=[\"travel\", \"running\", \"walking\"], inplace=True)\n",
    "df.drop(columns=[\"sex\", \"mounting\"], inplace=True)\n",
    "df.drop(columns=[\"piloerection\"], inplace=True)\n",
    "df.drop(columns=[\"social_interaction\", \"nursing\"], inplace=True)\n",
    "df.drop(columns=[\"grooming\"], inplace=True)\n",
    "df.drop(columns=[\"display\", \"branch_shaking\", \"stone_throw\", \"drumming\"], inplace=True)\n",
    "df.drop(columns=[\"cross_species_interaction\"], inplace=True)\n",
    "df.drop(columns=[\"resting\"], inplace=True)\n",
    "df.drop(columns=[\"playing\"], inplace=True)\n",
    "df.drop(columns=[\"no_behaviour\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviours = [\n",
    "    \"p_camera_reaction\",\n",
    "    \"p_tool_use\",\n",
    "    \"p_object_carrying\",\n",
    "    \"p_bipedal\",\n",
    "    \"p_feeding\",\n",
    "    \"p_chimp_carrying\",\n",
    "    \"p_vocalisation\",\n",
    "    \"p_climbing\",\n",
    "    \"p_aggression\",\n",
    "    \"p_travel\",\n",
    "    \"p_sex\",\n",
    "    \"p_piloerection\",\n",
    "    \"p_social_interaction\",\n",
    "    \"p_grooming\",\n",
    "    \"p_display\",\n",
    "    \"p_cross_species_interaction\",\n",
    "    \"p_resting\",\n",
    "    \"p_playing\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6857 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6857/6857 [01:05<00:00, 104.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge 15-second rows into 1 representative multilabel\n",
    "store = []\n",
    "for video in tqdm(df.video_id.unique()):\n",
    "    tmp = df[df.video_id == video]\n",
    "    multilabel = tmp[behaviours].sum().ge(1).view(\"i1\").values\n",
    "    store.append(dict(video_id=video, label=multilabel))\n",
    "df = df.merge(pd.DataFrame(store), on=\"video_id\", how=\"left\")\n",
    "df.label = df.label.apply(lambda x: str(x.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"assign_full_video_multilabel.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metadata/text only model and video analogue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-dab5b1422ace>:1: DtypeWarning: Columns (0,26,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"assign_full_video_multilabel.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"assign_full_video_multilabel.csv\")\n",
    "df.label = df.label.apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter videos that need removing\n",
    "videos_to_remove = pd.read_csv(\"videos_to_remove.csv\")\n",
    "df = df[~df.video_id.isin(videos_to_remove.videos_to_remove.unique())]\n",
    "df = df[~df.video_id.isin([\"djo_cam09_0698421_0598444_20130109_pict0017\"])]\n",
    "df = df[~df.month.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sp\"] = df.tags.str.lower()\n",
    "df[\"sp\"] = df.sp.str.split(\",\")\n",
    "df.sp.fillna(\"\", inplace=True)\n",
    "df.sp = df.sp.apply(lambda x: list(enumerate(x)))\n",
    "\n",
    "df[\"sb\"] = df.behavior.str.lower()\n",
    "df[\"sb\"] = df.sb.str.split(\",\")\n",
    "df.sb.fillna(\"\", inplace=True)\n",
    "df.sb = df.sb.apply(lambda x: list(enumerate(x)))\n",
    "\n",
    "df[\"split_tags\"] = df.sp + df.sb\n",
    "df[\"split_tags\"] = df.split_tags.apply(lambda x: sorted(x, key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_tags(x, tag_df):\n",
    "    store = []\n",
    "    for i, t in enumerate(x):\n",
    "        tmp = tag_df[tag_df.Tags == t[-1]].drop_duplicates()\n",
    "        if len(tmp.index) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            extract = [x for x in tmp.values[0, 1:] if isinstance(x, str)]\n",
    "            if not extract:\n",
    "                continue\n",
    "            else:\n",
    "                store.append((t[0], extract))\n",
    "    return store\n",
    "\n",
    "\n",
    "df[\"new_tags\"] = df.split_tags.apply(lambda x: get_new_tags(x, tag_df))\n",
    "df.new_tags = df.new_tags.apply(lambda x: str(x.tolist()))\n",
    "df.label = df.label.apply(lambda x: str(x.tolist()))\n",
    "df.to_csv(\"clips_w_temporally_aligned_behaviours_tmp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-a91d8120f6f8>:1: DtypeWarning: Columns (0,26,27,29,71,72,73,76,80,81,83,85,86,87,88,89,90,92,93,96,98,101,104,105,106,107,108,110,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"clips_w_temporally_aligned_behaviours_tmp.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"clips_w_temporally_aligned_behaviours_tmp.csv\")\n",
    "# df.label = df.label.apply(lambda x: ast.literal_eval(x))\n",
    "# df.new_tags = df.new_tags.apply(lambda x: ast.literal_eval(x))\n",
    "# df.new_tags = df.new_tags.apply(lambda x: sorted(x, key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acp000dbgq', 'acp000dbgr', 'acp000dbgs', 'acp000dbgt',\n",
       "       'acp000dbvi', 'acp000dbvk', 'acp000dbvm', 'acp000dbvn'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)\n",
    "df[df.video_id == \"ngo_vid27_0216382_0050822_20130215_pict0002\"][\n",
    "    [\"video.id\", \"subject_id\", \"video_id\"]\n",
    "].subject_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviours = [\n",
    "    \"p_camera_reaction\",\n",
    "    \"p_tool_use\",\n",
    "    \"p_object_carrying\",\n",
    "    \"p_bipedal\",\n",
    "    \"p_feeding\",\n",
    "    \"p_chimp_carrying\",\n",
    "    \"p_vocalisation\",\n",
    "    \"p_climbing\",\n",
    "    \"p_aggression\",\n",
    "    \"p_travel\",\n",
    "    \"p_sex\",\n",
    "    \"p_piloerection\",\n",
    "    \"p_social_interaction\",\n",
    "    \"p_grooming\",\n",
    "    \"p_display\",\n",
    "    \"p_cross_species_interaction\",\n",
    "    \"p_resting\",\n",
    "    \"p_playing\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_dict = {\n",
    "    \"camera_reaction\": \"camera_reaction\",\n",
    "    \"tool_use\": \"(tool_use) | (termite_fishing) | (nut_cracking)\",\n",
    "    \"object_carrying\": \"object_carry\",\n",
    "    \"bipedal\": \"bipedal\",\n",
    "    \"feeding\": \"(feeding) | (wood_eating)\",\n",
    "    \"chimp_carrying\": \"chimp_carrying\",\n",
    "    \"vocalisation\": \"(vocalisation) | (hoot) | (grunt)\",\n",
    "    \"climbing\": \"climbing\",\n",
    "    \"aggression\": \"(aggression) | (charge) | (fight)\",\n",
    "    \"travel\": \"(travel) | (running) | (walking)\",\n",
    "    \"sex\": \"(sex) | (mounting)\",\n",
    "    \"piloerection\": \"piloerection\",\n",
    "    \"social_interaction\": \"(social_interaction) | (nursing)\",\n",
    "    \"grooming\": \"grooming\",\n",
    "    \"display\": \"(display) | (branch_shaking) | (stone_throw) | (drumming)\",\n",
    "    \"cross_species_interaction\": \"cross_species_interaction\",\n",
    "    \"resting\": \"resting\",\n",
    "    \"playing\": \"playing\",\n",
    "    \"no_behaviour\": \"(label_indicator == False) | (no_behaviour)\",\n",
    "}\n",
    "\n",
    "reversed_dict = {}\n",
    "for key, value in conditions_dict.items():\n",
    "    conditions = [condition.strip() for condition in value.split(\"|\")]\n",
    "    for condition in conditions:\n",
    "        reversed_dict[condition] = key\n",
    "\n",
    "modified_dict = {}\n",
    "for key, value in reversed_dict.items():\n",
    "    modified_key = key.replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "    modified_dict[modified_key] = value\n",
    "\n",
    "# Remove 'label_indicator' and 'no_behaviour' keys from modified_dict\n",
    "modified_dict.pop(\"label_indicator == False\")\n",
    "modified_dict.pop(\"no_behaviour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_tags(x, modified_dict):\n",
    "    store = []\n",
    "    for t in x:\n",
    "        if t[-1][0] in modified_dict.keys():\n",
    "            t[-1][0] = modified_dict[t[-1][0]]\n",
    "            store.append(t)\n",
    "    return store\n",
    "\n",
    "\n",
    "def order_tags(x):\n",
    "    store = []\n",
    "    tag_num = len(x)\n",
    "    for i in range(tag_num):\n",
    "        if x[i][1][0] not in store:\n",
    "            store.append(x[i][1][0])\n",
    "    return store\n",
    "\n",
    "\n",
    "# Decode multi hot binary labels to class labels\n",
    "def decode_label(x, behaviours):\n",
    "    decoded_behaviours = []\n",
    "    idxs = np.where(x)\n",
    "    for idx in idxs[0]:\n",
    "        decoded_behaviours.append(behaviours[idx].split(\"p_\")[-1])\n",
    "    return decoded_behaviours\n",
    "\n",
    "\n",
    "df[\"parent_new_tags\"] = df.new_tags.apply(lambda x: get_parent_tags(x, modified_dict))\n",
    "df[\"ordered_tags\"] = df.parent_new_tags.apply(lambda x: order_tags(x))\n",
    "df[\"decoded_labels\"] = df.label.apply(lambda x: decode_label(x, behaviours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)\n",
    "df.ordered_tags = df.ordered_tags.apply(lambda x: str(x))\n",
    "df.decoded_labels = df.decoded_labels.apply(lambda x: str(x))\n",
    "df[\n",
    "    [\"video_id\", \"subject_id\", \"start.time\", \"ordered_tags\", \"max\", \"decoded_labels\"]\n",
    "].drop_duplicates().tail(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.video_id == \"baf_vid16_0340989_1432398_20151114_12010009\"][\n",
    "    [\"start.time\", \"new_tags\", \"ordered_tags\", \"sb\", \"label\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create video dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "vdf = df[[\"video_id\", \"label\"]]\n",
    "vdf.label = vdf.label.apply(lambda x: x[:-1])  # let 0 vector represent no behaviour\n",
    "vdf.label = vdf.label.apply(lambda x: str(list(x)))\n",
    "vdf = vdf.drop_duplicates()\n",
    "\n",
    "\n",
    "vdf.label = vdf.label.apply(lambda x: ast.literal_eval(x))\n",
    "labels = np.array(list(vdf.label.values))\n",
    "X = vdf.video_id.to_numpy().reshape((6675, 1))\n",
    "\n",
    "assert len(X) == len(labels)\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, labels, test_size=0.30)\n",
    "X_test, y_test, X_val, y_val = iterative_train_test_split(\n",
    "    X_test, y_test, test_size=0.33\n",
    ")\n",
    "y_train, y_test, y_val = (\n",
    "    [str(list(x)) for x in y_train],\n",
    "    [str(list(x)) for x in y_test],\n",
    "    [str(list(x)) for x in y_val],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vdf = pd.DataFrame({\"video\": X_train[:, 0], \"label\": y_train})\n",
    "val_vdf = pd.DataFrame({\"video\": X_val[:, 0], \"label\": y_val})\n",
    "test_vdf = pd.DataFrame({\"video\": X_test[:, 0], \"label\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vdf.to_csv(\"data/annotations/video_only/train.csv\", index=False)\n",
    "val_vdf.to_csv(\"data/annotations/video_only/val.csv\", index=False)\n",
    "test_vdf.to_csv(\"data/annotations/video_only/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create meta-text dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition = [\"age_groups\", \"sex_groups\", \"min\", \"max\"]\n",
    "location = [\"country\", \"research_site\", \"location_metadata\", \"habitat\"]\n",
    "time = [\"day\", \"month\", \"year\", \"time_hr\", \"time_min\"]\n",
    "tdf = df[[\"video_id\"] + composition + location + time + [\"label\"]]\n",
    "tdf.label = tdf.label.apply(lambda x: x[:-1])  # let 0 vector represent no behaviour\n",
    "tdf.label = tdf.label.apply(lambda x: str(list(x)))\n",
    "tdf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age cats: 'unidentifiable', 'infant', 'juvenile', 'adolescent', 'adult'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_individual_age(x, age):\n",
    "    if age in x:\n",
    "        return x.count(age)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [\"unidentifiable\", \"infant\", \"juvenile\", \"adolescent\", \"adult\"]\n",
    "tdf.age_groups.fillna(\"\", inplace=True)\n",
    "tdf[\"unidentifiable_count\"] = tdf.age_groups.apply(\n",
    "    lambda x: count_individual_age(x.split(\",\"), \"unidentifiable\")\n",
    ")\n",
    "tdf[\"infant_count\"] = tdf.age_groups.apply(\n",
    "    lambda x: count_individual_age(x.split(\",\"), \"infant\")\n",
    ")\n",
    "tdf[\"juvenile_count\"] = tdf.age_groups.apply(\n",
    "    lambda x: count_individual_age(x.split(\",\"), \"juvenile\")\n",
    ")\n",
    "tdf[\"adolescent_count\"] = tdf.age_groups.apply(\n",
    "    lambda x: count_individual_age(x.split(\",\"), \"adolescent\")\n",
    ")\n",
    "tdf[\"adult_count\"] = tdf.age_groups.apply(\n",
    "    lambda x: count_individual_age(x.split(\",\"), \"adult\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sex cats: 'unclear', 'unidentifiable', 'male', 'female'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_individual_sex(x, sex):\n",
    "    if sex in x:\n",
    "        return x.count(sex)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexes = [\"unclear\", \"unidentifiable\", \"male\", \"female\"]\n",
    "tdf.sex_groups.fillna(\"\", inplace=True)\n",
    "tdf[\"unclear_count\"] = tdf.sex_groups.apply(\n",
    "    lambda x: count_individual_sex(x.split(\",\"), \"unclear\")\n",
    ")\n",
    "tdf[\"unidentifiable_count\"] = tdf.sex_groups.apply(\n",
    "    lambda x: count_individual_sex(x.split(\",\"), \"unidentifiable\")\n",
    ")\n",
    "tdf[\"male\"] = tdf.sex_groups.apply(lambda x: count_individual_sex(x.split(\",\"), \"male\"))\n",
    "tdf[\"female\"] = tdf.sex_groups.apply(\n",
    "    lambda x: count_individual_sex(x.split(\",\"), \"female\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_age_sex(age, sex):\n",
    "    assert len(age.split(\",\")), len(sex.split(\",\"))\n",
    "    pairings = []\n",
    "    for age, sex in zip(age.split(\",\"), sex.split(\",\")):\n",
    "        pair = f\"{age} {sex}\"\n",
    "        pairings.append(pair)\n",
    "    return \",\".join(pairings)\n",
    "\n",
    "\n",
    "tdf[\"age_sex_group\"] = tdf.apply(\n",
    "    lambda x: group_age_sex(x.age_groups, x.sex_groups), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_group = []\n",
    "for group in tdf[\"age_sex_group\"].unique():\n",
    "    for g in group.split(\",\"):\n",
    "        as_group.append(g)\n",
    "as_group = list(set(as_group))\n",
    "as_group = [i for i in as_group if i != \" \"]\n",
    "print(as_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_age_sex_pairs(x, g):\n",
    "    tmp = x.split(\",\")\n",
    "    count = tmp.count(g)\n",
    "    return count\n",
    "\n",
    "\n",
    "for g in as_group:\n",
    "    tdf[f\"{g}\"] = tdf.age_sex_group.apply(lambda x: count_age_sex_pairs(x, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[\"month\"] = tdf.month.astype(int)\n",
    "tdf[\"year\"] = tdf.year.astype(int)\n",
    "tdf.month = tdf.month.apply(lambda x: calendar.month_name[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_composition(x, pairings):\n",
    "    if x[\"max\"] == 1:\n",
    "        start = \"A video of\"\n",
    "        for pair in pairings:\n",
    "            if x[pair] == 1:\n",
    "                start += f\" {p.number_to_words(x[pair])} {pair} \"\n",
    "        start = start + \"chimpanzee\"\n",
    "    elif x[\"max\"] > 1:\n",
    "        start = (\n",
    "            f\"A video of {p.number_to_words(int(x['max']))} chimpanzees, composed of\"\n",
    "        )\n",
    "        tmp = []\n",
    "        for pair in pairings:\n",
    "            if x[pair] >= 1:\n",
    "                tmp.append(pair)\n",
    "\n",
    "        number_of_pairs = len(tmp)\n",
    "        only_one_pair = True if len(set(tmp)) == 1 else False\n",
    "\n",
    "        for i, pair in enumerate(tmp):\n",
    "            if only_one_pair:\n",
    "                start += f\" {p.number_to_words(x[pair])} {pair}s\"\n",
    "            elif i == number_of_pairs - 1:\n",
    "                start += f\" and {p.number_to_words(x[pair])} {pair}s\"\n",
    "            else:\n",
    "                if i == number_of_pairs - 2:\n",
    "                    start += f\" {p.number_to_words(x[pair])} {pair}s\"\n",
    "                else:\n",
    "                    start += f\" {p.number_to_words(x[pair])} {pair},\"\n",
    "        # start += f\" {p.number_to_words(x[pair])} {pair}s,\"\n",
    "    return start\n",
    "\n",
    "\n",
    "def desc_location(x):\n",
    "    return f\"It was filmed in {x['country']} at the {x['research_site']} research site\"\n",
    "\n",
    "\n",
    "def desc_habitat(x):\n",
    "    desc = f\"at a {x['location_metadata']} in {x['habitat']}\"\n",
    "    return desc\n",
    "\n",
    "\n",
    "def desc_time(x):\n",
    "    desc = f\"on {x['day']} {x['month']} {x['year']} at {x['time_hr']}:{x['time_min']}.\"\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairings = tdf.columns[24:-1]\n",
    "tdf[\"desc\"] = tdf.apply(\n",
    "    lambda x: f\"{desc_composition(x, pairings)}. {desc_location(x)} {desc_habitat(x)} {desc_time(x)}\",\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[tdf[\"max\"] == 5][[\"max\", \"desc\"]].desc.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tdf = train_vdf.merge(tdf, left_on=\"video\", right_on=\"video_id\", how=\"left\")\n",
    "train_tdf.rename(columns={\"label_y\": \"label\"}, inplace=True)\n",
    "train_tdf.drop(columns=[\"label_x\"], inplace=True)\n",
    "\n",
    "val_tdf = val_vdf.merge(tdf, left_on=\"video\", right_on=\"video_id\", how=\"left\")\n",
    "val_tdf.rename(columns={\"label_y\": \"label\"}, inplace=True)\n",
    "val_tdf.drop(columns=[\"label_x\"], inplace=True)\n",
    "\n",
    "test_tdf = test_vdf.merge(tdf, left_on=\"video\", right_on=\"video_id\", how=\"left\")\n",
    "test_tdf.rename(columns={\"label_y\": \"label\"}, inplace=True)\n",
    "test_tdf.drop(columns=[\"label_x\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tdf[[\"video_id\", \"descriptor\", \"label\"]].to_csv(\n",
    "    \"data/annotations/text_only/train_text_only.csv\", index=False\n",
    ")\n",
    "\n",
    "val_tdf[[\"video_id\", \"descriptor\", \"label\"]].to_csv(\n",
    "    \"data/annotations/text_only/val_text_only.csv\", index=False\n",
    ")\n",
    "\n",
    "test_tdf[[\"video_id\", \"descriptor\", \"label\"]].to_csv(\n",
    "    \"data/annotations/text_only/test_text_only.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"video_id\", \"split_tags\"]][\n",
    "    df[\"video_id\"] == \"tair_cam22_688836_647457_20131025_ek000246\"\n",
    "].groupby(\"video_id\").apply(lambda x: x.split_tags.values).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test embedding metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizer, CLIPTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "text_model = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "for module in text_model.text_model.encoder.layers[:-1].modules():\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "tokenized_text = tdf.descriptor.apply(\n",
    "    lambda x: tokenizer(\n",
    "        x, padding=\"max_length\", max_length=77, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = text_model(**tokenized_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is for temporal processing of the dataset #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\n",
    "    [\"video_id\", \"behavioral_context\", \"camera_\" \"start.time\"]\n",
    "    + list(test_df.columns[-19:])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = []\n",
    "for video_name in test_df.video_id.unique():\n",
    "    item = {}\n",
    "    tmp = test_df[test_df.video_id == video_name]\n",
    "    item[\"video_name\"] = video_name\n",
    "    item[\"metadata\"] = dict(\n",
    "        age_groups=tmp.age_groups, sex_groups=tmp.sex_groups, max=tmp.max, min=tmp.min\n",
    "    )\n",
    "    item[\"behaviour\"] = tmp[\"start.time\"].to_dict()\n",
    "    collection.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection[0][\"metadata\"][\"age_groups\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
