{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f95703b8c1fc>:1: DtypeWarning: Columns (0,26,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"merged_cns_maureen_annotations.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"merged_cns_maureen_annotations.csv\")\n",
    "df.label = df.label.apply(lambda x: ast.literal_eval(x)[:-1])\n",
    "df.classifications.fillna(\"nan\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label indicator\n",
    "attr = df.columns[-20:-2]\n",
    "df[\"label_indicator\"] = df[attr].apply(lambda x: 1 if x.sum() > 0 else 0, axis=1)\n",
    "df[\"label_count\"] = df[attr].apply(lambda x: x.sum(), axis=1)\n",
    "df[\"full_label_count\"] = df.label.apply(lambda x: sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count species classifications\n",
    "def count_blanks(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if i == \"blank\":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def count_chimps(x):\n",
    "    count = 0\n",
    "    for i in x:\n",
    "        if i == \"chimpanzee\" or i == \"chimp\":\n",
    "            count += 1\n",
    "            try:\n",
    "                split_i = i.split(\"/\")\n",
    "                if \"chimpanzee\" or \"chimp\" in split_i:\n",
    "                    count += 1\n",
    "            except:\n",
    "                continue\n",
    "    return count\n",
    "\n",
    "\n",
    "df[\"split_classifications\"] = df.classifications.apply(lambda x: x.lower().split(\",\"))\n",
    "df[\"blank_count\"] = df.split_classifications.apply(lambda x: count_blanks(x))\n",
    "df[\"classifications_count\"] = df.split_classifications.apply(lambda x: len(x))\n",
    "df[\"blank_ratio\"] = df.blank_count / df.classifications_count * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Videos which have been labelled but are empty!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will likely need to be removed but check beforehand\n",
    "empty_labelled_videos = df[\n",
    "    (df.behavioral_context == \"False\")\n",
    "    & (df[\"max\"].isna())\n",
    "    & (df[\"min\"].isna())\n",
    "    & (df.blank_ratio == 100.0)\n",
    "    & (df.label_indicator == 1)\n",
    "][\n",
    "    [\"subject_id\", \"video_id\", \"behavioral_context\", \"label_count\", \"max\", \"min\"]\n",
    "    + list(attr)\n",
    "].video_id.values.tolist()\n",
    "\n",
    "# These will likely need to be removed but check beforehand\n",
    "empty_labelled_videos.extend(\n",
    "    df[(df[\"max\"].isna()) & (df[\"min\"].isna()) & (df.label_indicator == 1)][\n",
    "        [\"subject_id\", \"video_id\", \"behavioral_context\", \"label_count\", \"max\", \"min\"]\n",
    "        + list(attr)\n",
    "    ].video_id.values.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'djo_cam05_0697652_0598620_20121226_pict0087',\n",
       " 'djo_cam10_0698763_0597847_20130109_ek000008',\n",
       " 'nim_vid01_0545838_0820109_20130923_ek000228',\n",
       " 'tair_cam15_687357_648673_20131220_pict0313',\n",
       " 'tair_cam15_687357_648673_20131220_pict0368',\n",
       " 'tair_cam1_687372_648736_20131223_pict0678',\n",
       " 'tair_cam22_688836_647457_20131025_ek000246',\n",
       " 'tair_cam24_685978_649225_20131123_pict0271',\n",
       " 'tair_cam25_688407_650454_20130611_pict0377',\n",
       " 'tair_cam28_688388_651361_20130625_ek000290',\n",
       " 'tair_cam30_687126_648216_20130904_ek000287',\n",
       " 'tair_cam31_686481_649929_20131209_ek000529'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(empty_labelled_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Videos not labelled that should be!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['travel', 'climbing', 'resting', 'displaying', 'feeding',\n",
       "       'unclear', 'camera reaction', 'aggression', 'tool use', 'playing',\n",
       "       'greeting', 'grooming', 'sexual', 'tool use algae', 'reassurance',\n",
       "       'tool use termites', 'tool use nuts', 'False',\n",
       "       'tool use stone throwing'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.behavioral_context.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bipedal_mm\n",
       "False    53883\n",
       "True      1364\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.camera_reaction_mm.replace(\"ues\", True, inplace=True)\n",
    "df.camera_reaction_mm.replace(\"False\", False, inplace=True)\n",
    "df.camera_reaction_mm.replace(\"True\", True, inplace=True)\n",
    "df.camera_reaction_mm.value_counts()\n",
    "\n",
    "df.tool_use_mm.replace(\"ues\", True, inplace=True)\n",
    "df.tool_use_mm.replace(\"False\", False, inplace=True)\n",
    "df.tool_use_mm.replace(\"True\", True, inplace=True)\n",
    "df.tool_use_mm.value_counts()\n",
    "\n",
    "df.vocalization_mm.replace(\"ues\", True, inplace=True)\n",
    "df.vocalization_mm.replace(\"False\", False, inplace=True)\n",
    "df.vocalization_mm.replace(\"offscreen\", False, inplace=True)\n",
    "df.vocalization_mm.replace(\"True\", True, inplace=True)\n",
    "df.vocalization_mm.value_counts()\n",
    "\n",
    "df.bipedal_mm.replace(\"ues\", True, inplace=True)\n",
    "df.bipedal_mm.replace(\"False\", False, inplace=True)\n",
    "df.bipedal_mm.replace(\"True\", True, inplace=True)\n",
    "df.bipedal_mm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_videos = df[(df.behavioral_context != \"False\") & (df.full_label_count == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-501e014a1fc9>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_videos.p_travel = unlabelled_videos.apply(\n",
      "<ipython-input-11-501e014a1fc9>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_videos.p_climbing = unlabelled_videos.apply(\n",
      "<ipython-input-11-501e014a1fc9>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_videos.p_feeding = unlabelled_videos.apply(\n",
      "<ipython-input-11-501e014a1fc9>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_videos.p_resting = unlabelled_videos.apply(\n",
      "<ipython-input-11-501e014a1fc9>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_videos.p_tool_use = unlabelled_videos.apply(\n",
      "<ipython-input-11-501e014a1fc9>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_videos.p_camera_reaction = unlabelled_videos.apply(\n"
     ]
    }
   ],
   "source": [
    "# Process behavioural context\n",
    "\n",
    "unlabelled_videos.p_travel = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if ((x[\"behavioral_context\"] == \"travel\") & (x[\"p_travel\"] == False))\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_climbing = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if ((x[\"behavioral_context\"] == \"climbing\") & (x[\"p_climbing\"] == False))\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_feeding = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if ((x[\"behavioral_context\"] == \"feeding\") & (x[\"p_feeding\"] == False))\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_resting = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if ((x[\"behavioral_context\"] == \"resting\") & (x[\"p_resting\"] == False))\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_tool_use = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if ((x[\"behavioral_context\"] == \"tool use\") & (x[\"p_tool_use\"] == False))\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_camera_reaction = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if (\n",
    "        (x[\"behavioral_context\"] == \"camera reaction\")\n",
    "        & (x[\"p_camera_reaction\"] == False)\n",
    "    )\n",
    "    else False,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process camera reaction, tool use, vocalization, bipedal\n",
    "unlabelled_videos.p_camera_reaction = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if (\n",
    "        ((x[\"camera_reaction_mm\"] == True) & (x[\"p_camera_reaction\"] == False))\n",
    "        | ((x[\"camera_reaction_mm\"] == True) & (x[\"p_camera_reaction\"] == True))\n",
    "    )\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_tool_use = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if (\n",
    "        ((x[\"tool_use_mm\"] == True) & (x[\"p_tool_use\"] == False))\n",
    "        | ((x[\"tool_use_mm\"] == True) & (x[\"p_tool_use\"] == True))\n",
    "    )\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_vocalization = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if (\n",
    "        ((x[\"vocalization_mm\"] == True) & (x[\"p_vocalisation\"] == False))\n",
    "        | ((x[\"vocalization_mm\"] == True) & (x[\"p_vocalisation\"] == True))\n",
    "    )\n",
    "    else False,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "unlabelled_videos.p_bipedal = unlabelled_videos.apply(\n",
    "    lambda x: True\n",
    "    if (\n",
    "        ((x[\"bipedal_mm\"] == True) & (x[\"p_bipedal\"] == False))\n",
    "        | ((x[\"bipedal_mm\"] == True) & (x[\"p_bipedal\"] == False))\n",
    "    )\n",
    "    else False,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing these videos for now since they are highly ambiguous\n",
    "unlabelled_videos.video_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos to remove\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"videos_to_remove\": list(\n",
    "            set(empty_labelled_videos + unlabelled_videos.video_id.values.tolist())\n",
    "        )\n",
    "    }\n",
    ").to_csv(\"videos_to_remove.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species_classifications = []\n",
    "df[\"split_classifications\"] = df.classifications.apply(lambda x: x.lower().split(\",\"))\n",
    "for row in df.split_classifications.values:\n",
    "    for i in row:\n",
    "        unique_species_classifications.append(i)\n",
    "unique_species_classifications = list(set(unique_species_classifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion - blank is only ever used alone...\n",
    "blank_categories = []\n",
    "for item in unique_species_classifications:\n",
    "    if item == \"blank\":\n",
    "        blank_categories.append(item)\n",
    "    else:\n",
    "        try:\n",
    "            split_item = item.split(\"/\")\n",
    "            for i in split_item:\n",
    "                if i == \"blank\":\n",
    "                    blank_categories.append(item)\n",
    "        except:\n",
    "            continue\n",
    "blank_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminate bogus classifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species_classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
